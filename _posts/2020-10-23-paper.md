# GASNet: Weakly-supervised Framework for COVID-19 Lesion Segmentation
# GASNet：COVID-19病变分割的弱监督框架


Abstract— Segmentation of infected areas in chest CT volumes is of great significance for further diagnosis and treatment of COVID-19 patients. Due to the complex shapes and varied appearances of lesions, a large number of voxellevel labeled samples are generally required to train a lesion segmentation network, which is a main bottleneck for developing deep learning based medical image segmentation algorithms. In this paper, we propose a weaklysupervised lesion segmentation framework by embedding the Generative Adversarial training process into the Segmentation Network, which is called GASNet. GASNet is optimized to segment the lesion areas of a COVID-19 CT by the segmenter, and to replace the ‘abnormal’ appearance with a generated ‘normal’ appearance by the generator, so that the ‘restored’ CT volumes are indistinguishable from healthy CT volumes by the discriminator. GASNet is supervised by chest CT volumes of many healthy and COVID-19 subjects without voxel-level annotations. Experiments on three public databases show that when using as few as one voxel-level labeled sample, the performance of GASNet is comparable to fully-supervised segmentation algorithms trained on dozens of voxel-level labeled samples.
摘要—在胸部CT区域中分割感染区域对于进一步诊断和治疗COVID-19患者具有重要意义。由于病变的形状复杂且外观多样，通常需要大量体素标记的样本来训练病变分割网络，这是开发基于深度学习的医学图像分割算法的主要瓶颈。在本文中，我们通过将生成的对抗训练过程嵌入到称为GASNet的分割网络中，提出了一种弱监督的病变分割框架。 GASNet经过优化，可通过分割器分割COVID-19 CT的病变区域，并通过发生器生成的“正常”外观替换“异常”外观，从而使“恢复的” CT体积与健康CT难以区分鉴别者的数量。 GASNet由许多健康和COVID-19受试者的胸部CT量进行监督，而没有体素水平注释。在三个公共数据库上进行的实验表明，当使用少至一个体素级别的标记样本时，GASNet的性能可与在数十个体素级别的标记样本上训练的完全监督分割算法相媲美。
Index Terms— Convolution Neural Network, COVID-19, GAN, Weakly-supervised Segmentation
索引词-卷积神经网络，COVID-19，GAN，弱监督分割
## I. INTRODUCTION
## 一 引言
THE epidemic of coronavirus disease 2019 (COVID-19) is raging around the world. Chest CT can detect small lesion areas due to its high spatial resolution and therefore is an effective imaging tool for monitoring the disease [1] [2]. Automatic segmentation of lesion areas of a COVID-19 CT can facilitate medical experts in diagnosing by focusing on the Region of Interest (RoI) instead of the whole volume. Besides, statistics related to the lesion area are part of the criteria for determining the severity [3] [4]. However, this task is challenging as the lesion areas are extremely varied. Three typical COVID19 CT scans from a public dataset [5] are shown in Fig. 1. It can be seen that the lesions range from small to large, and the appearance may be of ground glass opacity, consolidation, or mixed type. Due to blurry and indistinguishable boundaries between infected and healthy areas, voxel-level labeling of lesions is not only time-consuming, but also tends to contain inconsistency between different annotators. Fig. 1 also shows the infectious annotation as ground truth (GT) along with the dataset and the manual segmentation results by two other radiologists. Since the boundary of the infected area is very fuzzy, even the segmentation results given by two experienced radiologists have obvious inconsistencies with GT.
2019年冠状病毒病（HEVID-19）流行在全球范围内肆虐。胸部CT由于具有较高的空间分辨率，因此可以检测出较小的病变区域，因此是一种用于监测疾病的有效成像工具[1] [2]。通过将重点放在目标区域（RoI）而不是整个体积上，可以对COVID-19 CT的病变区域进行自动分割，以帮助医学专家进行诊断。此外，与病变部位有关的统计数据是确定严重程度的标准之一[3] [4]。但是，由于病变区域千差万别，该任务具有挑战性。图1显示了来自公共数据集[5]的三种典型的COVID19 CT扫描。可见病变范围从小到大，并且外观可能是毛玻璃不透明，合并或混合型。由于受感染区域与健康区域之间的边界模糊且难以区分，因此病变的体素级标记不仅耗时，而且往往会包含不同注释者之间的不一致。图1还显示了作为地面真相（GT）的传染性注释以及数据集和其他两名放射科医生的手动分割结果。由于感染区域的边界非常模糊，因此即使由两位经验丰富的放射科医生给出的分割结果也与GT明显不一致。
Deep learning shown encouraging performance for lesion segmentation of COVID-19 CT, but only when a sufficient amount of labeled data such as thousands of slices is available [6] [7] [8] [9]. It takes more than 200 minutes on average to annotate the lesion area of one COVID-19 CT volume [8]. The high cost of collecting expert annotations is a big obstacle to the development of medical image segmentation algorithms for new diseases like COVID-19.
深度学习对COVID-19 CT的病变分割显示出令人鼓舞的性能，但只有在有足够数量的标记数据（例如数千个切片）时才可用[6] [7] [8] [9]。 注释一个COVID-19 CT体积的病变区域平均要花费200多分钟[8]。 收集专家注释的高昂费用是开发针对像COVID-19这样的新疾病的医学图像分割算法的一大障碍。
Data augmentation [10] [11] and image synthesis [12] [13] may alleviate the lack of pixel/voxel-level annotations to a varying degree. Self-learning or active learning [14] [15] [16] updates the segmentation model by iteratively providing pseudo label to the unlabeled data, and hopes to gradually improve the precision. Other methods try to make up for the lack of pixel/voxel-level supervision information by using image/volume-level labels, such as Class Activation Maps (CAMs) [17], Generative Adversarial Network (GAN) [18], and Multiple Instance Learning (MIL) [19]. However, these methods have more or less the following problems: (1) a certain number of samples with pixel/voxel-level annotations are still necessary; (2) using pseudo-label data may introduce noise; and (3) the mapping from volume-level annotation information to voxel-level segmentation is usually not accurate enough. Detailed comment on related medical image segmentation methods is provided in section II.
数据增强[10] [11]和图像合成[12] [13]可以在不同程度上缓解像素/体素级别注释的缺失。 自学习或主动学习[14] [15] [16]通过向未标记的数据迭代提供伪标签来更新分割模型，并希望逐步提高精度。 其他方法试图通过使用图像/体积级标签来弥补像素/体素级监督信息的不足，例如，类激活图（CAM）[17]，生成对抗网络（GAN）[18]和多重 实例学习（MIL）[19]。 但是，这些方法或多或少具有以下问题：（1）仍然需要一定数量的具有像素/体素级别注释的样本； （2）使用伪标签数据可能会引入噪声； （3）从体积级注释信息到体素级分割的映射通常不够准确。 第二部分提供了有关医学图像分割方法的详细评论。
Our idea is to ‘restore’ the CT volume of a COVID-19 patients to the status when he/she is healthy by combining a segmentation network and a generative network. Restoration performance is supervised by a discriminator that is trained using CT scans of many healthy people and COVID-19 patients (without voxel-level labeling of lesion areas). This scheme is feasible since a large number of volume-level labels, indicating whether a CT volume is COVID-19 positive or not, are directly available from diagnosis results in COVID-19 designated hospitals and more reliable [20] than voxel-level annotations obtained manually. The proposed framework is designed to mine the potential knowledge contained in many COVID-19 positive and negative CT volumes by embedding Generative Adversarial training in a standard Segmentation Network, referred to as GASNet, and hence its demand for voxel-level annotations is very small. Fig. 2 shows the pipeline of GASNet. Both the generator and the segmenter take a COVID-19 CT volume as input, and the two outputs together with the original CT volume are fused to form a synthetic healthy volume. Both real and synthetic healthy volumes are fed to the discriminator. In the training process, the goal of the discriminator is to distinguish between the synthetic healthy volume and the real healthy volume, while the goal of the generator and the segmenter is to deceive the discriminator. Such an adversarial training strategy will push the segmenter to segment the lesion areas of a COVID-19 CT as precisely as possible. We also propose a simple but effective strategy of synthesizing COVID-19 CT volumes with voxel-level pseudolabels during the adversarial training process, which further improves the segmentation performance of GASNet. A detailed description of the algorithm will be given in section III.
我们的想法是通过组合分割网络和生成网络，将COVID-19患者的CT容量“恢复”到他/她健康的状态。鉴别器对恢复性能进行监督，该鉴别器使用许多健康人和COVID-19患者的CT扫描进行训练（没有病变区域的体素水平标记）。该方案是可行的，因为可以从COVID-19指定医院的诊断结果中直接获得大量的体积级别标签，表明CT体积是否为COVID-19阳性，并且比体素级别注释更可靠[20]。手动获得。拟议的框架旨在通过将生成的对抗训练嵌入到称为GASNet的标准细分网络中来挖掘许多COVID-19正负CT量中包含的潜在知识，因此对体素级注释的需求非常小。图2显示了GASNet的管道。生成器和分段器均以COVID-19 CT体积作为输入，并且将两个输出与原始CT体积融合在一起以形成合成健康体积。实际和人工合成的健康量均被送入鉴别器。在训练过程中，鉴别器的目的是区分合成健康量和真实健康量，而生成器和分割器的目的是欺骗鉴别器。这种对抗训练策略将推动分割器尽可能精确地分割COVID-19 CT的病变区域。我们还提出了一种简单而有效的策略，在对抗训练过程中使用体素水平的伪标记合成COVID-19 CT量，从而进一步提高了GASNet的细分效果。该算法的详细说明将在第三节中给出。
Compared with other weakly-supervised methods, a major advantage of GASNet lies in utilizing volume-level labels in an adversarial learning way, alleviating the burden of voxel-level annotation and maintaining a good segmentation performance at the same time. When using only one voxel-level labeled sample in training, GASNet obtains a 70% Dice score on a public COVID-19 lesion segmentation dataset [5], comparable to representative fully-supervised algorithms (U-Net [21], VNet [22], and UNet++ [23]) requiring a large number of voxel-level annotated samples. Code of GASNet is available at https://github.com/xzwthu/GASNet. Details of the experiments are in section IV and section V.
与其他弱监督方法相比，GASNet的主要优势在于以对抗性学习方式利用卷级标签，减轻了体素级注释的负担，同时保持了良好的分割性能。 在训练中仅使用一个体素水平标记的样本时，GASNet在公共COVID-19病变分割数据集[5]上获得70％的Dice分数，与具有代表性的完全监督算法（U-Net [21]，VNet [22 ]和UNet ++ [23]）需要大量的体素级注释样本。 GASNet的代码可从https://github.com/xzwthu/GASNet获得。 实验的详细信息在第四部分和第五部分中。
## II. RELATED WORK
## 二 相关工作
In this section, we first introduce existing public COVID19 CT databases containing lesion annotation, then review current COVID-19 lesion segmentation methods both in fullysupervised and weakly-supervised way, and finally describe recent weakly-supervised methods and GAN methods in general medical image segmentation.
在本节中，我们首先介绍现有的包含病变注释的公共COVID19 CT数据库，然后以完全监督和弱监督的方式回顾当前的COVID-19病变分割方法，最后描述一般医学图像分割中最近的弱监督方法和GAN方法 。
A. Public COVID-19 CT segmentation datasets
A.公开的COVID-19 CT分割数据集
Performance evaluation using public datasets is very important for comparing different image segmentation algorithms. Being an emerging research direction, most COVID-19 studies are conducted independently [6] [7] [8], using non-public data. Very recently, a few public databases are available [5] [24] [25]. Giving a brief description of these databases is necessary before we discuss performance of different algorithms. We summarize the current public COVID-19 CT segmentation datasets in Table I. Detailed descriptions are in section IV.
使用公共数据集进行性能评估对于比较不同的图像分割算法非常重要。 作为新兴的研究方向，大多数COVID-19研究是使用非公开数据独立进行的[6] [7] [8]。 最近，有一些公共数据库可用[5] [24] [25]。 在讨论不同算法的性能之前，有必要对这些数据库进行简短描述。 我们在表I中汇总了当前的公共COVID-19 CT分割数据集。详细说明在第IV节中。
B. Fully-supervised COVID-19 lesion segmentation
B.完全监督的COVID-19病变分割
Most of the COVID-19 lesion segmentation methods [6] [7] [8] are based on U-Net [21] structure or its modifications, containing an encoding path and a decoding path, which are connected by skip connection at the corresponding resolution. Zhang et al. [6] adopt a two-stage segmentation framework for segmenting lung lesions into five classes. They train on a total of 4,695 CT slice images with voxel-level annotations and obtain an mDICE score of 58.7%. Wu et al. [7] jointly train a segmentation network and a classification network, using over 144K slices including 3,855 voxel-level labeled CT scan slices from 200 COVID-19 patients. They obtain a 78.3% Dice score on their dataset. Shan et al. [8] use a 3D VB-Net as the backbone and employ a Human-In-TheLoop (HITL) strategy to train the network on 400 CT volumes. The HITL strategy reduces the annotation time and improves the accuracy. The net time spent on labeling data is still more than 176 hours, and they report a 91% Dice score on their own dataset. However, [7] [8] have not published their codes, neither did they report their performance on public datasets. We reproduce the network structures of these works and test their performance on Dataset-A [5] following a 5-fold cross-validation strategy. The performance is slightly improved compared with a normal U-Net network, with Dice scores of 64% and 63%, while the performance of U-Net is 62%. For more details, please refer to section V.
大多数COVID-19病变分割方法[6] [7] [8]基于U-Net [21]结构或其修改，包含编码路径和解码路径，它们通过相应位置处的跳过连接来连接解析度。张等。 [6]采用两阶段分割框架将肺部病变分为五类。他们在总共4695幅具有体素级别注释的CT切片图像上进行训练，并获得58.7％的mDICE分数。 Wu等。 [7]联合训练分割网络和分类网络，使用超过144K切片，包括来自200名COVID-19患者的3,855个体素级标记的CT扫描切片。他们在数据集中获得78.3％的骰子得分。 Shan等。 [8]使用3D VB-Net作为骨干网，并采用“人在环（HITL）”策略在400个CT量上训练网络。 HITL策略减少了注释时间并提高了准确性。用于标记数据的净时间仍超过176小时，并且他们在自己的数据集中报告Dice得分为91％。但是，[7] [8]尚未发布其代码，也未在公共数据集上报告其性能。我们复制了这些作品的网络结构，并按照5倍交叉验证策略在Dataset-A [5]上测试了它们的性能。与正常的U-Net网络相比，Dice得分分别为64％和63％，性能略有提高，而U-Net的性能为62％。有关更多详细信息，请参阅第V节。
Besides U-Net, other deep models have also been used for COVID-19 lesion segmentation. Fan et al. [27] propose modules named Parallel Partial Decoder and Reverse Attention Module to improve lesion segmentation performance. They also conduct a test with semi-supervised strategy, collecting an unlabeled dataset and giving pseudo values iteratively, and gain a Dice score of 59.7% on Dataset-B [24]. Qiu et al. [9] propose a lightweight 2D model pre-trained on ImageNet dataset [28] and obtain performance comparable to heavy models like the fully convolutional network (FCN) [29] structure (77% VS 75%) on a dataset consisting of 110 axial CT slices from ∼60 patients with COVID-19 [30].
除了U-Net，其他深层模型也已用于COVID-19病变分割。 范等。 [27]提出了名为并行部分解码器和反向注意模块的模块，以提高病变分割性能。 他们还使用半监督策略进行测试，收集未标记的数据集并迭代给出伪值，并在Dataset-B上获得59.7％的Dice分数[24]。 邱等。 [9]提出了在ImageNet数据集上进行预训练的轻量级2D模型[28]，并在由110个轴组成的数据集上获得了与重模型（如全卷积网络（FCN）[29]结构（77％VS 75％））相当的性能。 约60例COVID-19患者的CT切片[30]。
C.Weakly-supervised COVID-19 lesion segmentation
C.弱监督的COVID-19病变分割
The latest research begins to explore lesion segmentation of COVID-19 volumes in weakly-supervised scenarios. Laradji et al. [31] propose to train a neural network with active learning on a point-level annotation scenario. Yao et al. [32] design a set of simple operations to synthesize lesion-like appearances, generate paired training datasets by superimposing synthesized lesions on the lung regions of healthy images, and train a model to predict the healthy lung part of the input. A set of specially designed methods combining threshold selection, morphological processing, and region growth are used to determine the lesion segmentation during the test. Zhang et al. [33] also use the GAN network as we do, but the purpose of GAN in their method is to perform data augmentation based on existing voxel-level labeled samples, so as to generate more paired samples with pseudo labels. Two segmentation networks, ENet [34] and U-Net, are trained to verify the effectiveness of the proposed data augmentation.
最新的研究开始探索在弱监督情况下COVID-19体积的病变分割。 Laradji等。 [31]提出在点级注释场景中训练带有主动学习的神经网络。姚等。 [32]设计了一组简单的操作来合成病变样外观，通过将合成病变叠加在健康图像的肺区域上来生成配对的训练数据集，并训练模型来预测输入的健康肺部。一组专门设计的方法结合了阈值选择，形态学处理和区域增长来确定测试过程中的病变分割。张等。 [33]也像我们一样使用GAN网络，但是GAN在他们的方法中的目的是基于现有体素级标记的样本执行数据增强，从而生成更多带有伪标记的配对样本。训练了两个分割网络ENet [34]和U-Net，以验证所提出的数据增强的有效性。
Different from the above methods, we focus on designing a weakly-supervised segmentation framework under volumelevel label supervision. Our framework simultaneously trains the GAN and the segmentation network and dynamically extracts the volume-level annotation information through adversarial learning, thus minimizing the requirement for voxellevel annotations. The comparison of GASNet with the above methods on the division of dataset, the number of annotations, and performance of segmentation are given in Table II, and a more detailed comparison will be given in section IV.
与上述方法不同，我们着重设计在体积级标签监督下设计的弱监督细分框架。 我们的框架同时训练GAN和分割网络，并通过对抗性学习动态提取体积级别的注释信息，从而最大程度地减少了对体素级别注释的需求。 表II给出了GASNet与上述方法在数据集划分，注解数量和分割性能方面的比较，第四节给出了更详细的比较。
D. Weakly-supervised medical image segmentation
D.弱监督医学图像分割
Various methods of using weak annotations have been proposed in medical image segmentation area. Several works are devoted to the use of extra but sparse annotations, including scribbles [35], points [36] [37], and bounding boxes [38] [39]. Scribbles and points require labeling at least one scribble or point for each RoI and the labeled areas will be used to calculate the segmentation loss directly. As for the unlabeled part, Wang et al. [36] propose generating initial segments via a random walker algorithm [40], and then train a fullysupervised segmentation network. Qu et al. [37] propose a similar pipeline using a different method for label generation, combining K-means clustering results and Voronoi partition diagram. Instead of generating a pseudo label for the unlabeled areas, Valvano et al. [35] directly predict the segmentation results by adding shape constraints through multi-GAN to make the segmentation results look realistic at multi-scales. Bounding boxes provide a more well-refined position constraint for segmentation but are more time-consuming for annotation [38] [39].
在医学图像分割领域中已经提出了使用弱注释的各种方法。一些作品致力于使用额外但稀疏的注释，包括涂鸦[35]，点[36] [37]和边界框[38] [39]。涂鸦和点需要为每个RoI至少标记一个涂鸦或点，并且标记的区域将用于直接计算分割损失。至于未标记的部分，Wang等。 [36]提出通过随机沃克算法[40]生成初始片段，然后训练一个完全监督的分割网络。 Qu等。 [37]提出了一种类似的管道，使用不同的方法来生成标签，结合了K-means聚类结果和Voronoi分区图。 Valvano等人没有为未标记区域生成伪标记。 [35]通过使用多GAN增加形状约束来直接预测分割结果，使分割结果在多尺度下看起来很逼真。边界框为分割提供了更完善的位置约束，但对于注释则更耗时[38] [39]。
The major limitation of the aforementioned approaches is relying on additional dataset annotations, which can be time-consuming and is prone to errors (for example, not all voxels in the bounding box should be positive; scribbles and points annotation can miss challenging labeled samples), and the errors can be propagated to the models during training. Methods using GAN, such as [35] even need unpaired real segmentation masks, which are voxel-level labeled, as the real samples for the discriminator.
前述方法的主要局限性是依赖于附加的数据集注释，这可能很耗时并且容易出错（例如，并非边界框中的所有体素都应为正；乱写和点注释可能会遗漏具有挑战性的标记样本） ，并且误差可以在训练期间传播到模型。 使用GAN的方法（例如[35]）甚至需要不成对的真实分割蒙版（已被体素级别标记）作为鉴别器的真实样本。
Weakly-supervised learning under volume-level label supervision earns increasing interest in medical image segmentation because it adds no annotation burden. Xu et al. [41] enrich the volume-level labels to instance-level labels by multiple instance learning (MIL) and segment histopathology images using only volume-level labels. However, MIL shows unsatisfactory performance on lesion segmentation of COVID19 as shown in section IV. Feng et al. [42] propose a method especially for pulmonary nodules segmentation that learns discriminative regions from the activation maps of convolution units (CAM) in an image classification model. Ouyang et al. [43] employ the attention masks derived from a volume-level classification model as the voxel-level masks for weakly-annotated data. Because the attention masks are rough and inaccurate, hundreds of voxel-level annotations are still necessary for accurate lesion segmentation like pneumothorax segmentation in chest X-ray [43].
在卷级标签监督下的弱监督学习对医学图像分割越来越感兴趣，因为它不增加注释负担。 徐等。 [41]通过多个实例学习（MIL）将卷级标签丰富到实例级标签，并仅使用卷级标签分割组织病理学图像。 但是，如第四节所示，MIL对COVID19的病变分割表现不理想。 冯等。 [42]提出了一种特别用于肺结节分割的方法，该方法从图像分类模型中的卷积单元（CAM）的激活图学习区分区域。 欧阳等。 [43]采用从体量分类模型得到的注意遮罩作为弱注释数据的体素水平遮罩。 由于注意口罩粗糙且不准确，因此仍需要数百个体素级别的注释来进行精确的病变分割，例如胸部X光片中的气胸分割[43]。
E. GAN for medical image segmentation
E. GAN用于医学图像分割
GAN is increasingly adopted as an assistance to medical image segmentation task. The mainstream directions of GAN based methods include: (1) synthesizing more available training sample pairs [12] [13] [44], where GAN is a tool for data augmentation, and the training of segmentation network has no feedback on the quality of synthetic data. (2) Adapting domain to leverage external labeled datasets [45] [46] [35]. The external dataset is required to contain enough pixel/voxel-level labeled training samples. And (3) considering the segmentation network as a generator and designing the discriminator as a structure of FCN [29] to obtain a confidence map of segmentation prediction, and thus helping the optimization of the segmentation network based on it [15] [47] [48]. Such methods do not use volume-level annotation, and their requirement for voxel-level labeled samples is considerable.
GAN被越来越多地用作医疗图像分割任务的辅助工具。 基于GAN的方法的主流方向包括：（1）合成更多可用的训练样本对[12] [13] [44]，其中GAN是数据增强的工具，而分段网络的训练对质量的反馈没有反馈。 综合数据。 （2）调整域以利用外部标记的数据集[45] [46] [35]。 要求外部数据集包含足够的像素/体素级别的标记训练样本。 （3）将分割网络视为一个生成器，并将鉴别器设计为FCN的结构[29]以获得分割预测的置信度图，从而帮助基于分割网络的优化[15] [47] [48]。 这种方法不使用体积级别的注释，并且它们对体素级别的标记样本的要求很高。
## III. PROPOSED METHOD
## 三 建议的方法

In this section, we first illustrate the pipeline of GASNet. Then, we describe the auxiliary constraint terms in the form of loss functions used to make the training more stable and GASNet perform better. We will also detail a simple but effective method of generating COVID-19 positive CT volumes with voxel-level pseudo-label to improve the segmentation performance of GASNet. Finally, we provide the implementation details, including the specific structure, data preprocessing, and the training hyperparameters.
在本节中，我们首先说明GASNet的管道。 然后，我们以损失函数的形式描述辅助约束项，以使训练更稳定并且GASNet表现更好。 我们还将详细介绍一种简单而有效的方法，利用体素级伪标记生成COVID-19阳性CT量，以改善GASNet的分割性能。 最后，我们提供了实现细节，包括特定的结构，数据预处理和训练超参数。
A. GASNet
A.气体网络
GASNet consists of three modules: the generator (G), the discriminator (D), and the segmenter (S). The data input to GASNet includes a small amount of voxel-level labeled data Il , and a large amount of volume-level labeled data Id and Ih, where Id is the diseased volume data and Ih is the healthy volume data. Our method is based on a simple fact: the appearance of a lesion area contains the most obvious feature to distinguish COVID-19 CT from healthy CT. We train a segmenter that can provide segmentation masks and utilize a generator to replace the predicted lesion area with a generated one whose appearance is close to the uninfected area while maintaining the uninfected area. If the synthetic healthy volumes successfully deceive the binary classifier, which is the discriminator in GASNet, we can obtain an accurate enough segmentation result. The synthetic volume is fomulated by:
GASNet包含三个模块：生成器（G），鉴别器（D）和分段器（S）。 输入到GASNet的数据包括少量的体素水平标记的数据Il和大量的体积水平标记的数据Id和Ih，其中Id是患病的体积数据，Ih是健康的体积数据。 我们的方法基于一个简单的事实：病变区域的外观包含将COVID-19 CT与健康CT区别开的最明显特征。 我们训练了一种分割器，该分割器可以提供分割蒙版，并利用生成器将生成的生成器替换为预计的病变区域，该生成器的外观与未感染区域接近，同时保持未感染区域。 如果合成健康卷成功欺骗了二进制分类器（即GASNet中的鉴别器），则我们可以获得足够准确的分割结果。 合成体积的计算公式为：
where Mˆ = S(Id; θS) is the probabilistic segmentation mask predicted by S, Ig = G(Id; θG) is the generated volume, and θS, θG are the learnable parameters of S and G respectively. To fully deceive the discriminator, the segmenter needs to segment all infected areas and the generator needs to generate confusing volumes at the predicted lesion area of the segmentation. In contrast, the discriminator will try to distinguish the synthetic volume from the real healthy one. We label the synthetic volume as 1 and the real healthy volume as 0, and train the GASNet in an adversarial way via the following minimax game:
其中Mˆ = S（Id;θS）是S预测的概率分割掩码，Ig = G（Id;θG）是生成的体积，θS，θG分别是S和G的可学习参数。 为了完全欺骗鉴别器，分割器需要分割所有感染区域，而生成器则需要在分割的预测病变区域产生令人困惑的体积。 相反，鉴别器将尝试将合成量与实际健康量区分开。 我们将合成量标记为1，将实际健康量标记为0，然后通过以下minimax游戏以对抗性方式训练GASNet：
where the objective function LGAN 1 is given by LGAN = EIh [log(1 − D(Ih; θD))] + EId [log(D(Is; θD))] where D(I; θD) is the prediction of the D, Is is fomulated by Eq 1, and θD represents the learnable parameters of D. As the formation of the synthetic volume is related to the prediction mask and the generated volume, gradient of LGAN can feed back to both the S and G. Also, we add a basic segmentation loss measuring the difference between the output of S and the GT of a small number of voxel-level labeled samples: LS 2 = CEL(Mˆ l , Ml), where Mˆ l = S(Il ; θS), Ml is the ground truth of the voxel-level labeled data Il .
其中目标函数LGAN 1由LGAN = EIh [log（1- D（Ih;θD））] + EId [log（D（Is;θD））]给出，其中D（I;θD）是 D，Is由等式1表示，θD代表D的可学习参数。由于合成体积的形成与预测掩码和生成的体积有关，因此LGAN的梯度可以反馈到S和G。 ，我们添加了一个基本的分段损失，用于测量少量体素级标记样本的S和GT的输出之间的差异：LS 2 = CEL（Mˆ l，Ml），其中M = l = S（Il;θS） M1是体素级标记数据Il的基本事实。
B. Auxiliary constraints in the form of loss functions
B.损失函数形式的辅助约束
Logically and theoretically, provided that we carefully train G, D, and S, the synthesized volume will be nearly close to the healthy volume. However, frameworks with GAN are generally difficult to train [48] [49] [50] [51]. The quality of the generator and the discriminator is the crux for our ultimate goal of segmenting infected areas accurately. Several auxiliary constraints are added to the loss functions to make the adversarial training more stable, leading to better performance
从逻辑和理论上讲，只要我们仔细训练G，D和S，合成的体积将接近健康体积。 然而，带有GAN的框架通常很难训练[48] [49] [50] [51]。 发生器和鉴别器的质量是我们精确分割受感染区域的最终目标的关键。 损失函数中添加了一些辅助约束，以使对抗训练更加稳定，从而提高性能
First, the naive GASNet contains defects of the bias of the input. The segmenter is fed with only diseased volumes in the original GASNet. This brings sample bias and leads to false-positive predictions on healthy samples during testing. For healthy CT volumes, we expect the predicted segmentation maps are all zero, and the output of the generator is a reconstructed volume of the original input. Therefore, the healthy volumes are also inputted into the segmenter and the generator. The cross entropy loss between S(Ih; θS) and Mh, where Mh are all zero, is added to LS.
首先，朴素的GASNet包含输入偏差的缺陷。 在原始GASNet中，分段器仅使用有病的卷。 这会带来样品偏差，并导致在测试过程中对健康样品产生假阳性预测。 对于健康的CT量，我们期望预测的分割图全部为零，并且生成器的输出是原始输入的重构量。 因此，健康体积也被输入到分段器和发生器中。 S（Ih;θS）和Mh之间的交叉熵损失（其中Mh全部为零）被添加到LS。
Second, no supervision constrains the parts of the generated volume where the segmentation values are close to zero because they are not used to form the synthetic volume, and the quality of the generated volume is uncontrollable due to the lack of the supervision signal. It becomes the bottleneck of improving the final performance of the segmenter. A reconstruction loss Lrecons constrains the output of the generator: Lrecons = MSE(G(Ih; θG), Ih), where MSE(·,·) is the mean square error function, alleviates the problem. We also introduce an additional loss LIgT oD = EId [log(D(G(Id; θG); θD)] to LGAN for further improvement by feeding the generated volume of Id into the D. Fig. 3 shows the comparison of the generated volumes before and after adding Lrecons and LIgT oD. We can see that the quality of the generated volume and the synthetic volume are significantly improved, so as to the performance of the segmenter, which will be detailed in section V. When the input of the S are healthy volumes, the forward propagation process of synthesis and discrimination is not needed, and LGAN will not be calculated.
其次，没有监督约束分段值接近零的生成体积部分，因为它们不用于形成合成体积，并且由于缺少监督信号，生成体积的质量不可控。它成为提高分段器最终性能的瓶颈。重建损耗Lrecons限制了发电机的输出：Lrecons = MSE（G（Ih;θG），Ih），其中MSE（·，·）是均方误差函数，可以缓解该问题。我们还向LGAN引入了额外的损耗LIgT oD = EId [log（D（G（Id;θG）;θD）]，以通过将生成的Id量输入到D中来进一步改善。图3显示了生成的Id的比较。在添加Lrecons和LIgT oD之前和之后的体积中，我们可以看到生成的体积和合成体积的质量得到了显着改善，从而提高了分段器的性能，这将在第五部分中详细介绍。 S是健康卷，不需要合成和区分的正向传播过程，并且不会计算LGAN。
As the training proceeds and the synthetic volume gets closer to the real healthy volume, the lesion signal that can be captured by the D becomes weaker and weaker. The D will tend to learn the noise signal between the data Is and Ih rather than the pathological signals, which leads to the performance collapse of the GASNet. Fig. 4 gives an example where performance collapse happens during training. The segmenter not only segmented the lesion area but also the healthy area, modifying both the pathological signals and the noise signals of the synthetic volume to confuse the discriminator. This leads to an extremely low segmentation performance.
随着训练的进行和合成体积越来越接近实际健康体积，D可以捕获的病变信号变得越来越弱。 D将倾向于学习数据Is和Ih之间的噪声信号，而不是病理信号，这将导致GASNet的性能崩溃。 图4给出了一个示例，其中在训练过程中发生了性能下降。 分割器不仅分割了病变区域，还分割了健康区域，同时修改了合成体积的病理信号和噪声信号，以使鉴别器混淆。 这导致极低的分割性能。
Inspired by the idea of dropout in the field of weakly supervised localization [52] [53] [54], where a dropout layer randomly determines whether to block the distinguishing features coming into the next layer of the classification network, we also feed the original diseased volume Id to the D in order to maintain the sensitivity and discriminability of the discriminator to the lesion signal during the training, meaning the dropout ratio is fixed at 0.5. A constraint loss LIdT oD = EId [log(D(Id; θD)] is added to LGAN , hoping that the D can always distinguish between volumes of the patients and the healthy people. Fig. 5 compares the training curves with and without the auxiliary constraint from LIdT oD and shows that LIdT oD alleviates the performance collapse of GASNet markedly.
受弱监督定位领域中的辍学想法的启发[52] [53] [54]，其中辍学层随机确定是否阻止区分特征进入分类网络的下一层，我们也将原始 D到D的疾病体积ID，以在训练过程中保持鉴别器对病变信号的敏感性和可区分性，这意味着辍学率固定为0.5。 LGAN中增加了一个约束损失LIdT oD = EId [log（D（Id;θD）]，希望D能够始终区分患者和健康人的体量，图5比较了有无条件下的训练曲线。 LIdT oD的辅助约束，表明LIdT oD显着缓解了GASNet的性能崩溃。
Finally, as the data Id has no voxel-level annotations, the final S may segment any lesion areas for some mild infected CT volumes. Inspired by MIL [19], we add a MIL loss to LS: LM IL = −log(max(S(Id; θS))), meaning at least one voxel of an diseased volume should be predicted as positive. To sum up, we extend loss functions LGAN and LS by adding four new losses as auxiliary constraints. The final objective function is defined as follow:
最后，由于数据Id没有体素级别的注释，因此最终的S可能会针对某些轻度感染的CT体积分割任何病变区域。 受MIL [19]的启发，我们向LS添加了MIL损失：LM IL = -log（max（S（Id;θS））），这意味着至少一个患病体积的体素应被预测为阳性。 综上所述，我们通过添加四个新损失作为辅助约束来扩展损失函数LGAN和LS。 最终目标函数定义如下：
C. Synthesize COVID-19 positive CT volumes with voxel-level pseudo-label
C.用体素水平的伪标记合成COVID-19阳性CT量
With the losses detailed in subsection III-B, GASNet can be trained stably and achieve good performance. We can further improve the segmentation performance by synthesizing COVID-19 positive CT volumes with voxel-level pseudo-label during the training process. Given an unlabeled COVID-19 data Id and its predicted lesion segmentation mask Mˆ = S(Id; θS), a healthy data Ih and its predicted lung mask Mlung where Mlung can be obtained by existing automatic algorithms [55], we can synthesize a COVID-19 positive volume Ips and its corresponding pseudo-label Mps as follows:
利用III-B小节中详细介绍的损失，可以稳定地训练GASNet并达到良好的性能。 我们可以通过在训练过程中使用体素水平的伪标记合成COVID-19阳性CT体积来进一步提高分割效果。 给定一个未标记的COVID-19数据Id及其预测的病灶分割掩码Mˆ = S（Id;θS），一个健康的数据Ih及其预测的肺罩Mlung，可以通过现有的自动算法获得Mlung [55]，我们可以合成一个 COVID-19阳性体积Ips及其对应的伪标记Mps如下：
where label 2 means voxels whose labels are not considered. We set ξ as 0.3 in our experiment. Different from the synthesis method in [32], in which the distribution and shpae of lesions added to the healthy volumes are artificailly defined, the lesion area of our synthetic data is dynamically extracted from the real COVID-19 positive volumes. Different from [33], in which the synthetic volume is generated through complex cascade generative networks given a label map of lesion and lung, our synthetic data is formed by simple linear weighted fusion of real infectious areas and real health volumes. Fig. 7 gives three examples of Ips and corresponding Mps. The synthetic COVID-19 volumes look very natural and diverse. Relying on the generated paired data Ips and Mps, we can alleviate the problem of insufficient voxel-level labeled samples by adding corresponding voxel-level cross entropy loss Lps = CSL(S(Ips; θs), Mps) to LS during the training. Lps boosts the segmentation performance of GASNet by 5.5% in our experiments, as shown in section V.
其中标签2表示未考虑其标签的体素。我们在实验中将ξ设置为0.3。与[32]中的合成方法不同，在合成方法中人为地定义了添加到健康卷中的病变的分布和分布，我们从真实的COVID-19阳性卷中动态提取了我们的合成数据的病变区域。与[33]不同的是，合成量是通过给定病灶和肺部标记图的复杂级联生成网络生成的，而我们的合成数据是由真实感染区和真实健康量的简单线性加权融合形成的。图7给出了Ips和相应Mps的三个示例。合成的COVID-19卷看起来非常自然多样。依靠生成的配对数据Ips和Mps，我们可以通过在训练过程中向LS添加相应的体素级交叉熵损失Lps = CSL（S（Ips;θs），Mps）来缓解体素级标记样本不足的问题。 Lps在我们的实验中将GASNet的细分性能提高了5.5％，如第五部分所示。
## D. Implementations
## D.实施
a) Data pre-processing: The 3D volume sample of each CT is cropped along the lung mask. The cropped volume is then resized into 40×160×160. Following the advice from [5], we clipped the value of CT volumes into [-1250,250]. As the tanh operation is used as the output of the generated volume, and the value of the output after a tanh operation ranges from - 1 to 1, we normalized the input volume into the same range. The automatic lung segmentation algorithm is based on an opensource pre-trained U-Net model [55]. This lung segmentation algorithm may not be perfect in some cases, but we just use it to get an approximate bounding box around the lung area. Lung segmentation of COVID-19 volumes are never used after pre-processing.
a）数据预处理：沿着肺罩裁剪每个CT的3D体积样本。 然后将裁剪后的体积调整为40×160×160。 根据[5]的建议，我们将CT量的值裁剪为[-1250,250]。 由于将tanh操作用作生成体积的输出，并且tanh操作之后的输出值的范围是-1到1，因此我们将输入体积归一化为相同范围。 自动肺分割算法基于开放源代码的预训练U-Net模型[55]。 在某些情况下，这种肺分割算法可能并不完美，但我们只是使用它来获得围绕肺区域的近似边界框。 在预处理之后，永远不会使用COVID-19量的肺分割。
b) The structure of GASNet: Without loss of generality, we adopt the standard U-Net structure as the segmenter of GASNet. Regarding the memory usage of the 3D volume, the number of the basic channel is reduced to 16 from 64 in the original paper. The generator and discriminator follows the structure of CycleGAN [56]. Following the advice in [57], we add the spectral normalization operation to the discriminator.
b）GASNet的结构：在不失一般性的前提下，我们采用标准的U-Net结构作为GASNet的分段器。 关于3D卷的内存使用情况，基本通道数从原始纸张的64个减少到16个。 生成器和鉴别器遵循CycleGAN [56]的结构。 根据[57]中的建议，我们将频谱归一化操作添加到鉴别器。
c) Training strategy and hyperparameters: Four datasets are required in order to train GASNet and get the best model, as shown in Algorithm 1. Since the target between training the S and the G and training the D is adversarial, we iteratively update their parameters using the corresponding loss in each step. Both LGAN and LS have contributions to the optimization of the segmenter, so there exists a hyperparameter λs to balance the two losses: LGAN + λsLS. As G and D are trained alternately, a hyperparameter θi controls the ratio of the number of times G and D are trained in each alternation. Validation is carried out every V aliter and only the parameters with the best performance on the validation dataset will be saved.
c）训练策略和超参数：训练GASNet并获得最佳模型需要四个数据集，如算法1所示。由于训练S和G与训练D之间的目标是对抗性的，因此我们迭代更新其参数 在每个步骤中使用相应的损失。 LGAN和LS都对分段器的优化做出了贡献，因此存在一个超参数λs来平衡LGAN +λsLS这两个损耗。 当G和D交替训练时，超参数θi控制每次交替训练G和D的次数之比。 每V升执行一次验证，并且仅保存验证数据集上具有最佳性能的参数。
## IV. EXPERIMENTS
## IV 实验内容
A. Dataset
A.数据集
We test the performance of our method on three public COVID-19 CT segmentation datasets [24] [25] [5]. Another public dataset with only slice-level annotations [30] used in [27] [9] is not suitable for GASNet for two reasons: (1) GASNet takes 3D CT volumes, rather than 2D slices as input; (2) annotations on slice-level, indicating whether a slice contains lesion area, are not directly available from diagnosis results.
我们在三个公开的COVID-19 CT分割数据集上测试了我们的方法的性能[24] [25] [5]。 [27] [9]中使用的仅带有切片级别注释的另一个公共数据集[30]不适合用于GASNet，这有两个原因：（1）GASNet采用3D CT体积而不是2D切片作为输入； （2）在切片级别上的注释（表示切片是否包含病变区域）不能直接从诊断结果中获得。
Dataset-A [5] consists of 20 CT volumes. Lungs and areas of infection were labeled by two radiologists and verified by an experienced radiologist. CT values of 10 volumes have been transformed to the range of [0,255]. Considering original CT values are unavailable, some work [32] did not test the performances on these volumes. We divide the dataset into subset1 (original CTs) and subset2 (10 transformed CTs), like [32] [33], and report the separate and overall performances.
数据集A [5]由20个CT卷组成。 肺部和感染部位由两名放射科医生标记，并由经验丰富的放射科医生进行验证。 10个体积的CT值已转换为[0,255]的范围。 考虑到原始CT值不可用，一些工作[32]并未测试这些卷的性能。 我们将数据集分为子集1（原始CT）和子集2（10个转换的CT），例如[32] [33]，并报告其单独的性能和总体性能。
Dataset-B [24] consists of 9 COVID-19 CT volumes with voxel-level annotations by a radiologist.
数据集B [24]由9个COVID-19 CT卷组成，并由放射科医生进行了体素级注释。
Dataset-C and Dataset-D (Volume-level annotation) are from MosMed [25], which consists of 856 CT volumes with COVID-19 related findings as well as 254 CT volumes without such findings. 50 COVID-19 cases have voxel-level annotations of lesions by experts, which forms Dataset-C. The rest of the data, consisting of 254 healthy volumes and 806 COVID-19 volumes excluding 50 voxel-level labeled samples, forms Dataset-D. The diagnosis results of the CT volumes can be used as volume-level labels directly.
数据集-C和数据集-D（卷级注释）来自MosMed [25]，由856个具有COVID-19相关发现的CT卷和254个无这些发现的CT卷组成。 由专家对50例COVID-19病例进行了体素水平的病变注解，形成了数据集C。 其余数据由254个健康卷和806个COVID-19卷组成，不包括50个体素水平标记的样本，形成了数据集D。 CT量的诊断结果可以直接用作量级标签。
Dataset-E (Volume-level annotation) is a large dataset with volume-level annotation we collected, in which 1,678 COVID-19 CT volumes come from the Wuhan Union Hospital, whose patients have been diagnosed as COVID-19 positive by nucleic acid testing, and 1,031 healthy CT volumes come from the routine physical examination.
数据集E（量级注释）是我们收集的具有量级注释的大型数据集，其中1,678份COVID-19 CT量来自武汉协和医院，其患者通过核酸检测被诊断为COVID-19阳性 ，以及1,013例健康的CT量来自常规的身体检查。
B. Experimental settings
B.实验设置
For training, all volume-level labeled data in Dataset-E is used to optimize GASNet. As for voxel-level labeled data, one volume randomly selected from Dataset-A is used for training and all of the rest, including 19 cases of Dataset-A and all volumes from Dataset-B and Dataset-C, are used for the test. Since Dataset-D comes from the same source as Dataset-C, we finetune GASNet using the volume-level Dataset-D when testing the performance on Dataset-C. The finetuned model is marked as GASNetf inetune.
为了进行培训，使用Dataset-E中的所有卷级标记数据来优化GASNet。 对于体素水平标记的数据，使用从Dataset-A中随机选择的一卷进行训练，其余所有数据（包括19例Dataset-A案例和Dataset-B和Dataset-C的所有卷）用于测试 。 由于Dataset-D与Dataset-C来自同一来源，因此在测试Dataset-C的性能时，我们使用卷级Dataset-D来微调GASNet。 经过微调的模型标记为GASNetf inetune。
As for the hyperparameters, λs is set to 100; θi is set to 5, meaning GASNet optimizes D 5 times each time it optimizes S and G. GASNet is trained jointly from scratch (without pretraining), with a batch size of 4, learning ratio of 1e-5 for the D and the S and 1e-4 for the S. Lps is not calculated in the first 7,000 iterations as we found the predicted mask for Id is prone to errors at first. Simple data augmentation techniques, including random cropping, Gaussian noise, and rotation lead to slight improvement on the test dataset. It takes about 24 hours (∼14,000 iterations) for training using a Titan RTX GPU with a 24G memory. During the test, voxels greater than 0.5 in the probabilistic segmentation mask Mˆ are predicted to be lesion (1), and those smaller than 0.5 are predicted to be healthy (0).
对于超参数，将λs设置为100。 θi设置为5，表示GASNet每次优化S和G时都会优化D 5次。GASNet从头开始进行联合训练（无预训练），批量大小为4，D和S的学习比率为1e-5。 和S. Lps的1e-4不会在前7,000次迭代中计算，因为我们发现ID的预测掩码起初容易出错。 简单的数据增强技术（包括随机裁剪，高斯噪声和旋转）导致测试数据集的轻微改进。 使用带有24G内存的Titan RTX GPU进行培训大约需要24小时（约14,000次迭代）。 在测试过程中，概率分割蒙板M 1中大于0.5的体素被认为是病变（1），小于0.5的体素被认为是健康的（0）。
C. Results
C.结果
We adopt typical metrics in COVID-19 lung infection quantification [58] [8], i.e. the Dice Score, Sensitivity, and Specificity for evaluation.
我们在COVID-19肺部感染的量化中采用典型指标[58] [8]，即骰子评分，敏感性和特异性进行评估。
Dice Score measures the overlap between the prediction and the ground truth: Dice = 2×T P 2×T P +F P +F N , where TP, FP, and FN are the number of true positive, false positive, and false negative voxels of one CT volume.
骰子分数测量预测值与基本事实之间的重叠：骰子= 2×TP 2×TP + FP + FN，其中TP，FP和FN是一台CT的真实正，错误正和错误负体素的数量 卷。
Sensitivity measures the fraction of real positive samples that are predicted correctly: Sensitivity = T P T P +F N .
灵敏度测量正确预测的真实阳性样本的比例：灵敏度= T P T P + F N。
Specificity measures the fraction of real negative samples that are predicted correctly: Specif icity = T N F P +T N .
特异性衡量正确预测的真实阴性样品的比例：特异性= T N F P + T N。
Quantitative results of GASNet and other small sample learning work on COVID-19 segmentation testing on three public datasets are shown in Table III and IV. We also reproduce the MIL strategy to represent the mainstream weaklysupervised methods in general medical image segmentation, together with a standard segmentation network, which is a U-Net structure in our experiment. Because different methods used inconsistent division strategies for datasets, the tables also show the number of training samples and testing samples used by each method on each dataset. In order to understand the difficulty of COVID-19 lesion segmentation, two radiologists from Wuhan Union Hospital annotated cases of Dataset-A in voxel level independently and their performances are measured by comparing with the ground truth of Dataset-A. The Dice scores of two radiologists are 73.5% and 73.9%, while GASNet achieves 70.3%. Comparing with other existing works, only LabelFree [32] and CoSinGAN [33] use less voxel-level labeled samples in training (zero and one slice from one sample) than GASNet, but GASNet exceeds their performance with a large margin. Other methods including [31] [59] and 3D nnU-Net [60] from the SegBenchmark [5] use more training samples and their performance can not match that of GASNet.
表III和IV显示了GASNet和其他小样本学习工作在三个公共数据集上进行COVID-19细分测试的定量结果。我们还再现了MIL策略，以代表一般医学图像分割中主流的弱监督方法，以及标准分割网络，该网络是我们实验中的U-Net结构。由于不同的方法对数据集使用不一致的划分策略，因此表中还显示了每种方法对每个数据集使用的训练样本和测试样本的数量。为了了解COVID-19病灶分割的难度，武汉协和医院的两名放射科医生分别以体素水平注释了Dataset-A病例，并通过与Dataset-A的地面真实性进行比较来评估其表现。两位放射科医生的Dice得分分别为73.5％和73.9％，而GASNet得分为70.3％。与其他现有作品相比，只有LabelFree [32]和CoSinGAN [33]在训练中使用的体素级标记样本（一个样本零个和一个切片）比GASNet少，但是GASNet大大超过了它们的性能。 SegBenchmark [5]中的其他方法，包括[31] [59]和3D nnU-Net [60]，使用的训练样本更多，其性能无法与GASNet媲美。
Qualitatively, visualization of the output of GASNet on four samples from the test datasets is shown in Fig. 8. The generated volume looks like a blurry version of the original input, except for the predicted lesion areas. The appearance in the predicted lesion areas changes a lot, making the generated volume look closer to a real healthy volume. Therefore, GASNet replaces the lesion areas of the original diseased volume with the corresponding parts of the generated volume, which makes the synthetic volume look quite similar to real healthy volumes. These examples show that GASNet does optimize its parameters to reach the goal of restoring original healthy CT volumes as we expect.
定性地，在图8中显示了GASNet在来自测试数据集的四个样本上的输出的可视化。生成的体积看起来像原始输入的模糊版本，除了预测的病变区域。 预计病变区域的外观变化很大，使生成的体积看起来更接近实际的健康体积。 因此，GASNet用生成的体积的相应部分替换了原始患病体积的病变区域，这使得合成体积看上去与真实的健康体积非常相似。 这些示例表明，GASNet确实优化了其参数，以达到我们期望的恢复原始健康CT量的目标。
The segmentation results of three samples using different methods are shown in Fig. 9. Compared with the standard 3D U-Net baseline and Multi-Instance Learning method, GASNet holds obvious advantages in eliminating both false positive and false negative. Fig. 10 shows three cases where GASNet has relatively poor performance. The first CT volume contains a small lesion, while GASNet missed it. In the second case, the lesion segmentation of GASNet is partially missing near the edge of lung. In the third case, the lesion area is so complex that annotations of the two radiologists and the ground truth are inconsistent, while the segmentation of GASNet is closer to those of radiologists.
使用不同方法对三个样本进行分割的结果如图9所示。与标准3D U-Net基线和多实例学习方法相比，GASNet在消除假阳性和假阴性方面均具有明显的优势。 图10显示了GASNet性能相对较差的三种情况。 第一个CT体积包含一个小的病变，而GASNet则没有。 在第二种情况下，GASNet的病变分割在肺边缘附近部分缺失。 在第三种情况下，病变区域是如此复杂，以至于两位放射科医生的注释和地面真相不一致，而GASNet的分割更接近放射科医生。
## V. ABLATION STUDY
## 五. 消融研究
A. Number of the voxel-level labeled samples
A.体素水平标记的样本数
To understand the impact of the number of training samples with voxel-level annotations, we use 1 sample, 4 samples, 20 samples and 45 samples respectively from Dataset-C as voxel-level labeled samples, use Dataset-D as volume-level labeled samples to train GASNet, and test the performance their performance on Dataset-A. We also train the baseline, i.e., using only a corresponding number of voxel-level labeled samples to train the standard U-Net network.
为了了解带有体素级别注释的训练样本数量的影响，我们分别使用来自Dataset-C的1个样本，4个样本，20个样本和45个样本作为体素级别标记的样本，使用Dataset-D作为体积级别的标记 样本以训练GASNet，并在Dataset-A上测试其性能。 我们还训练基线，即仅使用相应数量的体素水平标记的样本来训练标准U-Net网络。
Besides of 3D U-Net, we also adopt 3D VB-Net [22] and U-Net++ [23] as the segmenter of GASNet and test the performance following the same experimental scenario. The Dice scores on the test dataset of all the experiments are shown in Fig. 11. Note that 3D VB-Net is also the network used in [8]. The performance of GASNet, no matter which segmentation model is used as the segmenter of GASNet, is always better than that of the corresponding baseline, which demonstrates the robustness of the framework.
除了3D U-Net，我们还采用3D VB-Net [22]和U-Net ++ [23]作为GASNet的分段器，并在相同的实验场景下测试性能。 所有实验的测试数据集上的Dice得分如图11所示。请注意，3D VB-Net也是[8]中使用的网络。 无论使用哪种细分模型作为GASNet的细分工具，GASNet的性能始终都优于相应的基线，这证明了该框架的稳健性。
B. Improvement for segmentation performance by different auxiliary loss functions and Lps
B.通过不同的辅助损失函数和Lps改进分割性能
As demonstrated in subsection III-B, auxiliary constraints added as loss functions benefit the training of GASNet and the final performance. We quantitatively analyzed the ability of different constraints to improve the final segmentation performance by gradually adding the constraint losses to the framework. The quantitative results are shown in Table V. Each auxiliary constraint benefits the performance, with LIgT oD and LIdT oD benefiting the most. As shown in Fig. 3 and Fig. 5, LIgT oD improves the quality of the generated volume and LIdT oD alleviates the performance collapse of GASNet. Compared with the original GASNet without any auxiliary constraints, the Dice score has cumulatively risen more than 10 percent, proving the great impact of auxiliary constraints on network training. Lps further improves the segmentation performance of GASNet from 64.75% to 70.3%, by adding reliable supervision signal in voxel-level to the segmenter of GASNet.
如第III-B小节所述，作为损失函数添加的辅助约束有利于GASNet的培训和最终性能。 我们通过逐步将约束损失添加到框架中，定量分析了不同约束条件改善最终分割效果的能力。 定量结果显示在表V中。每个辅助约束对性能都有好处，其中LIgT oD和LIdT oD受益最大。 如图3和图5所示，LIgT oD可以提高生成量的质量，LIdT oD可以缓解GASNet的性能下降。 与没有任何辅助约束的原始GASNet相比，Dice分数累计上升了10％以上，证明了辅助约束对网络训练的巨大影响。 通过将可靠的体素级监督信号添加到GASNet的分段器中，Lps进一步将GASNet的分段性能从64.75％提高到70.3％。
## VI. CONCLUSION
## VI 结论
We propose a weakly-supervised framework for COVID19 infection segmentation, named GASNet. Utilizing volumelevel annotation information, GASNet needs only a single voxel-level labeled sample to obtain performance comparable to fully-supervised methods. Several auxiliary constraint losses benefit the training of GASNet, improving the segmentation performance and the quality of the synthetic volumes. Extensive experiments demonstrate the robustness of the algorithm. Given that volume-level labels are directly available as diagnosis results, GASNet is valuable in medical practice.
我们提出了一个针对COVID19感染细分的弱监督框架，名为GASNet。 利用体积级别的注释信息，GASNet仅需要单个体素级别的标记样本即可获得与完全监督方法相当的性能。 一些辅助约束损失有利于GASNet的训练，提高了分割性能和合成体积的质量。 大量实验证明了该算法的鲁棒性。 鉴于可以直接获得卷标标签作为诊断结果，因此GASNet在医学实践中很有价值。
However, more research on explaining and improving the framework is necessary, including embedding state-of-the-art segmentation structure to pull up the performance and relaxing some constraints used in this study. In the future, we will try to extend GASNet to handle multi-class segmentation tasks. Experiments on segmenting lesions of other diseases will also be carried out to valid the generalization of GASNet.
但是，有必要进行更多有关解释和改进框架的研究，包括嵌入最新的细分结构以提高性能并放松本研究中使用的一些约束。 将来，我们将尝试扩展GASNet以处理多类细分任务。 还将进行其他疾病的病变分割实验，以验证GASNet的推广。